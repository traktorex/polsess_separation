# ConvTasNet Stage 3 Configuration (8000 samples)
# Final search with refined hyperparameters

data:
  dataset_type: polsess
  batch_size: 3
  task: SB 
  num_workers: 1
  train_max_samples: 8000  # Scaled up from 4000
  val_max_samples: null    

model:
  model_type: convtasnet

  convtasnet:
    N: 256
    B: 256
    H: 512
    P: 3
    X: 8
    R: 4
    C: 2
    norm_type: gLN
    kernel_size: 16
    stride: 8
    causal: false
    mask_nonlinear: relu

training:
  num_epochs: 80   # Scaled up for 8000 samples (from 50)
  lr: 0.001
  weight_decay: 1e-6
  grad_clip_norm: 5.0
  use_amp: true
  amp_eps: 0.0001
  device: cuda
  save_dir: checkpoints

  # Logging
  use_wandb: true
  wandb_project: polsess-separation
  log_level: INFO

  # Learning rate scheduler
  lr_factor: 0.5
  lr_patience: 3

  validation_variants: ["SER", "SE"]

  # Curriculum learning schedule
  # Extended schedule for larger subset
  curriculum_learning:
    - epoch: 1
      variants: ["C", "R"]
    - epoch: 3
      variants: ["C", "R", "SR", "S"]
    - epoch: 6
      variants: ["R", "SR", "S", "SE", "ER", "E", "SER"]
      lr_scheduler: start
