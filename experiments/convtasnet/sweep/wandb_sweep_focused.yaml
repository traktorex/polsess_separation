# Focused W&B Sweep for Standard Training
# Based on previous sweep showing weight_decay ~6e-5 works best
#
# Previous sweep findings:
# - Best weight_decay: 6.7e-5 (SI-SDR: 7.51 dB)
# - model_B=256, model_H=512 consistently in top runs
# - grad_clip_norm: varied, need to test 5-10 range
#
# Usage:
#   wandb sweep experiments/wandb_sweep_focused.yaml
#   wandb agent <sweep-id>

program: train_sweep.py
method: bayes
metric:
  name: val_si_sdr
  goal: maximize

parameters:
  config:
    value: experiments/baseline.yaml

  # FOCUS: Fine-tune around best value from previous sweep
  weight_decay:
    distribution: log_uniform_values
    min: 0.00002    # 2e-5 (3x lower than previous best)
    max: 0.0002     # 2e-4 (3x higher than previous best)

  # FIXED: Best architecture from previous sweep
  model_B:
    value: 256

  model_H:
    value: 512

  # TEST: Grad clipping in effective range
  grad_clip_norm:
    values: [5.0, 10.0]

  # FIXED: Memory-efficient batch configuration
  batch_size:
    value: 4

  # FIXED: Standard values
  lr:
    value: 0.001
  epochs:
    value: 50

# Early termination
early_terminate:
  type: hyperband
  min_iter: 10
  eta: 2
  s: 2
