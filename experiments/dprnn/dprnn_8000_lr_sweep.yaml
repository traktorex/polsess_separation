# DPRNN LR Scheduler Sweep Config (8K samples, 80 epochs)
# For Experiment B: Tuning lr_factor and lr_patience after proxy sweep

data:
  dataset_type: polsess
  batch_size: 16
  num_workers: 1
  prefetch_factor: 2
  task: SB 
  train_max_samples: 8000
 
model:
  model_type: dprnn
  dprnn:
    N: 64  
    kernel_size: 16
    stride: 8 
    C: 2 
    num_layers: 6 
    chunk_size: 100
    rnn_type: LSTM
    hidden_size: 128
    num_rnn_layers: 1
    dropout: 0.0
    bidirectional: true
    norm_type: ln

training:
  # Core hyperparameters - these will be set from proxy sweep results
  lr: 0.001          # Placeholder - override via sweep
  weight_decay: 0.00001  # Placeholder - override via sweep
  grad_clip_norm: 5.0    # Placeholder - override via sweep
  
  # LR scheduler params - these will be swept
  lr_factor: 0.7     # Placeholder - will be swept
  lr_patience: 3     # Placeholder - will be swept
  
  num_epochs: 80
  use_amp: true
  amp_eps: 0.0001
  save_dir: checkpoints
  save_all_checkpoints: false
  
  early_stopping_patience: 10
  
  # Logging
  use_wandb: true
  wandb_project: polsess-thesis-experiments
  log_level: INFO

  validation_variants: ["SER", "SE"]

  # Curriculum learning schedule (standard for 8K)
  curriculum_learning:
    - epoch: 1
      variants: ["C", "R"]
    - epoch: 4
      variants: ["C", "R", "SR", "S"]
    - epoch: 8
      variants: ["R", "SR", "S", "SE", "ER", "E", "SER"]
      lr_scheduler: start
