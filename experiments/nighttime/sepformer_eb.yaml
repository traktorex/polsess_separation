# SepFormer baseline configuration for PolSESS
# Based on "Attention is All You Need in Speech Separation" (Subakan et al. 2021)

data:
  dataset_type: polsess
  batch_size: 1  # Transformers use more memory
  num_workers: 1
  prefetch_factor: 2
  task: EB  # SepFormer designed for speaker separation
  train_max_samples: null
  val_max_samples: null

model:
  model_type: sepformer
  sepformer:
    N: 256  # Encoder channels
    kernel_size: 16
    stride: 8
    C: 1  # Number of speakers to separate
    causal: false
    num_blocks: 2  # Number of times to repeat SepFormer block
    num_layers: 8  # Transformer layers in both IntraT and InterT
    d_model: 256  # Transformer dimension
    nhead: 8  # Attention heads
    d_ffn: 1024  # Feed-forward dimension
    dropout: 0.0
    chunk_size: 250  # Dual-path chunk size
    hop_size: 125  # Dual-path hop size

training:
  lr: 0.00015  
  weight_decay: 0.0  
  grad_clip_norm: 5.0  
  lr_factor: 0.5  
  lr_patience: 2 
  num_epochs: 10  
  use_amp: true
  amp_eps: 0.0001
  save_dir: checkpoints/nighttime/sepformer_eb
  use_wandb: true
  wandb_project: nighttime
  wandb_entity: null
  wandb_run_name: sepformer-eb
  log_file: null
  log_level: INFO
  resume_from: null

  validation_variants: ["SER", "SE"]

  # Curriculum learning schedule
  curriculum_learning:
    - epoch: 1
      variants: ["R"]
    - epoch: 2
      variants: ["R", "SR", "S"]
    - epoch: 3
      variants: ["R", "SR", "S", "SE", "E", "SER"]
      lr_scheduler: start