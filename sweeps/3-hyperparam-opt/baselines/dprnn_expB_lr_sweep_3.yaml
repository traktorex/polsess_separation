# Experiment B: LR Scheduler Grid Search Template
# Template for creating per-config grid searches to tune lr_factor and lr_patience
# 
# USAGE: After proxy sweep completes, manually create 3 sweep configs:
# 1. Copy this template
# 2. Set lr, weight_decay, grad_clip_norm from top config
# 3. Update project name with config identifier (e.g., expB-lr-grid-config1)
# 4. Create sweep and run agent

program: train_sweep.py
method: grid  # Grid search - exhaustive over all combinations
metric:
  name: best_val_sisdr
  goal: maximize

# Early termination - kill obviously poor LR combinations
early_terminate:
  type: hyperband
  min_iter: 35  # Let LR scheduler show its effect (starts at epoch 10)
  s: 2
  eta: 3  # Conservative - only kills clear underperformers

parameters:
  # Base config
  config:
    value: experiments/dprnn/dprnn_8000_lr_sweep.yaml
  
  # LR scheduler parameters to grid search
  lr_factor:
    values: [0.40, 0.55, 0.70, 0.85]  # 4 values
  
  lr_patience:
    values: [2, 3, 4, 5]  # 4 values
  # Total: 4 × 4 = 16 combinations per config
  
  # Fixed core hyperparameters - SET THESE FROM PROXY SWEEP TOP CONFIG
  lr:
    value: 0.0006715877864718136  # REPLACE with value from proxy sweep config
  
  weight_decay:
    value: 0.0000036280453014677834  # REPLACE with value from proxy sweep config
  
  grad_clip_norm:
    value: 11.699974467575942  # REPLACE with value from proxy sweep config

# Run configuration - UPDATE for each config
project: polsess-thesis-experiments
name: 3-dprnn-b-lr-grid-config3  # REPLACE X with 1, 2, or 3

# Notes:
# - Grid search: 16 runs per config (exhaustive)
# - Total: 3 configs × 16 runs = 48 runs
# - Estimated: ~72h without Hyperband (90 min/run)
# - No early termination - all combos are reasonable, want complete results
# - After all 3 grids complete, select best LR params for each config
# - Then run final validation: 3 configs × 3 seeds × 80 epochs on 16K (~27h)
