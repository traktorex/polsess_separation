{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Model Testing\n",
    "\n",
    "This notebook provides an interactive interface for testing trained speech separation models with dropdown widgets.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Auto-discovers available checkpoints from the hierarchical structure\n",
    "- Dropdown selectors for model, task, variant, and sample\n",
    "- Single-button model loading and testing\n",
    "- Audio playback and waveform visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from config import Config\n",
    "from models import get_model\n",
    "from datasets import get_dataset\n",
    "from torchmetrics.audio import ScaleInvariantSignalDistortionRatio\n",
    "from evaluate import load_model_from_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Checkpoint Discovery\n",
    "\n",
    "Scan the checkpoint directory structure to find all available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_checkpoints(checkpoint_root='checkpoints'):\n",
    "    \"\"\"Discover all available checkpoints in hierarchical structure.\n",
    "    \n",
    "    Structure: checkpoints/{model_name}/{task}/{run_name}/*.pt\n",
    "    \n",
    "    Returns dict: {display_name: checkpoint_path}\n",
    "    \"\"\"\n",
    "    checkpoint_root = Path(checkpoint_root)\n",
    "    checkpoints = {}\n",
    "    \n",
    "    if not checkpoint_root.exists():\n",
    "        print(f\"Warning: Checkpoint directory {checkpoint_root} does not exist\")\n",
    "        return checkpoints\n",
    "    \n",
    "    # Scan for all .pt files\n",
    "    for pt_file in checkpoint_root.glob('**/*.pt'):\n",
    "        # Get relative path parts\n",
    "        path_parts = pt_file.relative_to(checkpoint_root).parts\n",
    "        \n",
    "        # Expected structure: model_name/task/run_name/checkpoint.pt\n",
    "        if len(path_parts) >= 4:\n",
    "            model_name = path_parts[0]\n",
    "            task = path_parts[1]\n",
    "            run_name = path_parts[2]\n",
    "            checkpoint_filename = path_parts[3]\n",
    "            \n",
    "            # Create display name with checkpoint filename\n",
    "            display_name = f\"{model_name}/{task}/{run_name}/{checkpoint_filename}\"\n",
    "            checkpoints[display_name] = str(pt_file)\n",
    "        # Also handle: model_name/task/checkpoint.pt (if no run_name folder)\n",
    "        elif len(path_parts) == 3:\n",
    "            model_name = path_parts[0]\n",
    "            task = path_parts[1]\n",
    "            checkpoint_filename = path_parts[2]\n",
    "            \n",
    "            display_name = f\"{model_name}/{task}/{checkpoint_filename}\"\n",
    "            checkpoints[display_name] = str(pt_file)\n",
    "    \n",
    "    return checkpoints\n",
    "\n",
    "# Discover available checkpoints\n",
    "available_checkpoints = discover_checkpoints()\n",
    "\n",
    "if available_checkpoints:\n",
    "    print(f\"Found {len(available_checkpoints)} checkpoint(s):\")\n",
    "    for name in sorted(available_checkpoints.keys()):\n",
    "        print(f\"  - {name}\")\n",
    "else:\n",
    "    print(\"No checkpoints found. Train a model first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up dataset paths and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "# Try to get data root from config.py defaults, or use manual override\n",
    "try:\n",
    "    from config import DataConfig\n",
    "    config_defaults = DataConfig()\n",
    "    DATA_ROOT = Path(config_defaults.polsess.data_root)\n",
    "    print(f\"Using dataset path from config.py: {DATA_ROOT}\")\n",
    "except Exception as e:\n",
    "    # Fallback: User can manually set the path here\n",
    "    DATA_ROOT = Path(\"F:/PolSMSE/EksperymentyMOWA/BAZY/MOWA/PolSESS_C_both/PolSESS_C_both\")\n",
    "    print(f\"Using manual dataset path: {DATA_ROOT}\")\n",
    "    print(f\"(Could not load from config: {e})\")\n",
    "\n",
    "SAMPLE_RATE = 8000\n",
    "\n",
    "# Available variants for PolSESS\n",
    "VARIANTS = {\n",
    "    'C': 'Clean (no background)',\n",
    "    'S': 'Scene only',\n",
    "    'E': 'Event only',\n",
    "    'R': 'Reverb only',\n",
    "    'SE': 'Scene + Event',\n",
    "    'SR': 'Scene + Reverb',\n",
    "    'ER': 'Event + Reverb',\n",
    "    'SER': 'Scene + Event + Reverb'\n",
    "}\n",
    "\n",
    "# Tasks\n",
    "TASKS = {\n",
    "    'ES': 'Enhance Single speaker',\n",
    "    'EB': 'Enhance Both speakers',\n",
    "    'SB': 'Separate Both speakers'\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"Sample rate: {SAMPLE_RATE} Hz\")\n",
    "\n",
    "# Verify dataset path exists\n",
    "if not DATA_ROOT.exists():\n",
    "    print(f\"\\n⚠️  WARNING: Dataset path does not exist: {DATA_ROOT}\")\n",
    "    print(\"Please update DATA_ROOT in this cell to point to your PolSESS dataset\")\n",
    "else:\n",
    "    print(f\"✓ Dataset path verified: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Model Testing\n",
    "\n",
    "Use dropdown widgets to select model, task, variant, and sample, then test the model with a single button click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    \"\"\"Interactive model testing with dropdown widgets.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoints, data_root, sample_rate=16000):\n",
    "        self.checkpoints = checkpoints\n",
    "        self.data_root = Path(data_root)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.model = None\n",
    "        self.config = None\n",
    "        self.dataset = None\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Create widgets\n",
    "        self.checkpoint_dropdown = widgets.Dropdown(\n",
    "            options=sorted(checkpoints.keys()),\n",
    "            description='Checkpoint:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='600px')\n",
    "        )\n",
    "        \n",
    "        self.task_dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{k}: {v}\", k) for k, v in TASKS.items()],\n",
    "            description='Task:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        self.variant_dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{k}: {v}\", k) for k, v in VARIANTS.items()],\n",
    "            description='Variant:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        self.sample_id_text = widgets.IntText(\n",
    "            value=0,\n",
    "            description='Sample ID:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        self.show_plots_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Show waveform plots',\n",
    "            style={'description_width': '1px'},\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        self.load_button = widgets.Button(\n",
    "            description='Load Model',\n",
    "            button_style='info',\n",
    "            icon='download',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        self.test_button = widgets.Button(\n",
    "            description='Test Model',\n",
    "            button_style='success',\n",
    "            icon='play',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Button callbacks\n",
    "        self.load_button.on_click(self._on_load_clicked)\n",
    "        self.test_button.on_click(self._on_test_clicked)\n",
    "        \n",
    "        # Initially disable test button\n",
    "        self.test_button.disabled = True\n",
    "    \n",
    "    def _compute_pit_siSDR(self, estimate, clean, si_sdr_metric):\n",
    "        \"\"\"Compute permutation-invariant SI-SDR for speaker separation.\n",
    "        \n",
    "        Args:\n",
    "            estimate: [1, 2, T] - estimated speaker signals\n",
    "            clean: [2, T] - ground truth speaker signals\n",
    "            si_sdr_metric: SI-SDR metric function\n",
    "            \n",
    "        Returns:\n",
    "            best_sisdr_avg: Average SI-SDR for best permutation\n",
    "            best_sisdr1: SI-SDR for first speaker in best permutation\n",
    "            best_sisdr2: SI-SDR for second speaker in best permutation\n",
    "            best_perm: Best permutation index (0 or 1)\n",
    "        \"\"\"\n",
    "        # Permutation 1: est[0]->clean[0], est[1]->clean[1]\n",
    "        sisdr_perm1_spk1 = si_sdr_metric(estimate[:, 0:1, :], clean[0:1].unsqueeze(0))\n",
    "        sisdr_perm1_spk2 = si_sdr_metric(estimate[:, 1:2, :], clean[1:2].unsqueeze(0))\n",
    "        sisdr_perm1_avg = (sisdr_perm1_spk1 + sisdr_perm1_spk2) / 2\n",
    "        \n",
    "        # Permutation 2: est[0]->clean[1], est[1]->clean[0]\n",
    "        sisdr_perm2_spk1 = si_sdr_metric(estimate[:, 0:1, :], clean[1:2].unsqueeze(0))\n",
    "        sisdr_perm2_spk2 = si_sdr_metric(estimate[:, 1:2, :], clean[0:1].unsqueeze(0))\n",
    "        sisdr_perm2_avg = (sisdr_perm2_spk1 + sisdr_perm2_spk2) / 2\n",
    "        \n",
    "        # Choose best permutation\n",
    "        if sisdr_perm1_avg >= sisdr_perm2_avg:\n",
    "            return sisdr_perm1_avg, sisdr_perm1_spk1, sisdr_perm1_spk2, 0\n",
    "        else:\n",
    "            return sisdr_perm2_avg, sisdr_perm2_spk1, sisdr_perm2_spk2, 1\n",
    "    \n",
    "    def _on_load_clicked(self, b):\n",
    "        \"\"\"Load selected model checkpoint.\"\"\"\n",
    "        with self.output:\n",
    "            self.output.clear_output()\n",
    "            print(\"Loading model...\")\n",
    "            \n",
    "            try:\n",
    "                checkpoint_path = self.checkpoints[self.checkpoint_dropdown.value]\n",
    "                \n",
    "                # Use the new evaluation loading helper\n",
    "                self.model = load_model_from_checkpoint(\n",
    "                    checkpoint_path, \n",
    "                    config=None,  # Loads config from checkpoint\n",
    "                    device=self.device\n",
    "                )\n",
    "                \n",
    "                # Load checkpoint again to get metadata (model is already loaded)\n",
    "                checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "                \n",
    "                # Extract config for internal use\n",
    "                config_dict = checkpoint.get('config', {})\n",
    "                config_yaml_path = Path(checkpoint_path).parent / 'config.yaml'\n",
    "                if config_yaml_path.exists():\n",
    "                    with open(config_yaml_path, 'r') as f:\n",
    "                        config_dict = yaml.safe_load(f)\n",
    "                \n",
    "                from types import SimpleNamespace\n",
    "                \n",
    "                def dict_to_namespace(d):\n",
    "                    if isinstance(d, dict):\n",
    "                        return SimpleNamespace(**{k: dict_to_namespace(v) for k, v in d.items()})\n",
    "                    return d\n",
    "                \n",
    "                self.config = dict_to_namespace(config_dict)\n",
    "                \n",
    "                # Get model type for display\n",
    "                model_type = self.config.model.model_type\n",
    "                \n",
    "                print(f\"✓ Model loaded: {model_type}\")\n",
    "                print(f\"  Checkpoint: {checkpoint_path}\")\n",
    "                print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "                print(f\"  Val SI-SDR: {checkpoint.get('val_sisdr', 'N/A'):.2f} dB\")\n",
    "                print(f\"  Device: {self.device}\")\n",
    "                \n",
    "                # Enable test button\n",
    "                self.test_button.disabled = False\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error loading model: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                self.test_button.disabled = True\n",
    "    \n",
    "    def _on_test_clicked(self, b):\n",
    "        \"\"\"Test model on selected sample.\"\"\"\n",
    "        with self.output:\n",
    "            self.output.clear_output(wait=True)\n",
    "            print(\"Testing model...\")\n",
    "            \n",
    "            try:\n",
    "                task = self.task_dropdown.value\n",
    "                variant = self.variant_dropdown.value\n",
    "                sample_id = self.sample_id_text.value\n",
    "                \n",
    "                # Create dataset\n",
    "                DatasetClass = get_dataset('polsess')\n",
    "                dataset = DatasetClass(\n",
    "                    data_root=str(self.data_root),\n",
    "                    subset='test',\n",
    "                    task=task,\n",
    "                    allowed_variants=[variant]\n",
    "                )\n",
    "                \n",
    "                if sample_id >= len(dataset):\n",
    "                    print(f\"✗ Error: Sample ID {sample_id} out of range (max: {len(dataset)-1})\")\n",
    "                    return\n",
    "                \n",
    "                # Get sample\n",
    "                sample = dataset[sample_id]\n",
    "                mix = sample['mix'].unsqueeze(0).to(self.device)  # [1, T]\n",
    "                clean = sample['clean']  # [C, T] where C is num speakers (1 or 2)\n",
    "\n",
    "                # Get the mix file path from dataset metadata\n",
    "                mix_file_name = dataset.metadata.iloc[sample_id]['mixFile']\n",
    "                mix_file_path = dataset.data_root / 'test' / 'mix' / mix_file_name\n",
    "\n",
    "                print(f\"\\nMix file: {mix_file_name}\")\n",
    "                print(f\"Full path: {mix_file_path}\")\n",
    "                \n",
    "                # Handle different task types\n",
    "                is_separation = task == 'SB'  # Separate Both speakers\n",
    "                \n",
    "                # Run inference\n",
    "                with torch.no_grad():\n",
    "                    mix_input = mix.unsqueeze(1)  # [1, 1, T]\n",
    "                    estimate = self.model(mix_input)  # [1, C, T] for separation, [1, T] for enhancement\n",
    "                    estimate = estimate.cpu()\n",
    "                \n",
    "                # Compute SI-SDR based on task type\n",
    "                si_sdr_metric = ScaleInvariantSignalDistortionRatio()\n",
    "                \n",
    "                if is_separation:\n",
    "                    # For separation: use permutation-invariant SI-SDR\n",
    "                    if estimate.dim() == 3:  # [1, 2, T]\n",
    "                        # Compute PIT SI-SDR\n",
    "                        sisdr_avg, sisdr_spk1, sisdr_spk2, best_perm = self._compute_pit_siSDR(\n",
    "                            estimate, clean, si_sdr_metric\n",
    "                        )\n",
    "                        \n",
    "                        print(\"\\n\" + \"=\"*60)\n",
    "                        print(f\"Task: {task} | Variant: {variant} | Sample: {sample_id}\")\n",
    "                        print(\"=\"*60)\n",
    "                        print(f\"SI-SDR (Speaker 1):     {sisdr_spk1.item():>8.2f} dB\")\n",
    "                        print(f\"SI-SDR (Speaker 2):     {sisdr_spk2.item():>8.2f} dB\")\n",
    "                        print(f\"SI-SDR (Average):       {sisdr_avg.item():>8.2f} dB\")\n",
    "                        if best_perm == 1:\n",
    "                            print(f\"Note: Best permutation swapped speaker order\")\n",
    "                        print(\"=\"*60 + \"\\n\")\n",
    "                    else:\n",
    "                        raise ValueError(f\"Expected 3D output [1, 2, T] for separation, got {estimate.shape}\")\n",
    "                else:\n",
    "                    # For enhancement: clean is [T], estimate is [1, T]\n",
    "                    if clean.dim() > 1:\n",
    "                        clean = clean[0]  # Take first speaker if multi-channel\n",
    "                    \n",
    "                    si_sdr_mix = si_sdr_metric(mix.cpu(), clean.unsqueeze(0))\n",
    "                    si_sdr_estimate = si_sdr_metric(estimate, clean.unsqueeze(0))\n",
    "                    improvement = si_sdr_estimate - si_sdr_mix\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(f\"Task: {task} | Variant: {variant} | Sample: {sample_id}\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"SI-SDR (Mix):      {si_sdr_mix.item():>8.2f} dB\")\n",
    "                    print(f\"SI-SDR (Estimate): {si_sdr_estimate.item():>8.2f} dB\")\n",
    "                    print(f\"Improvement:       {improvement.item():>8.2f} dB\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                \n",
    "                # Visualize waveforms (only if checkbox is checked)\n",
    "                if self.show_plots_checkbox.value:\n",
    "                    if is_separation and estimate.dim() == 3:\n",
    "                        self._plot_separation_waveforms(\n",
    "                            mix.squeeze(0).cpu(),\n",
    "                            clean,\n",
    "                            estimate.squeeze(0)  # [2, T]\n",
    "                        )\n",
    "                    else:\n",
    "                        self._plot_waveforms(\n",
    "                            mix.squeeze(0).cpu(),\n",
    "                            clean.squeeze(0) if clean.dim() > 1 else clean,\n",
    "                            estimate.squeeze(0)\n",
    "                        )\n",
    "                \n",
    "                # Audio playback\n",
    "                if is_separation:\n",
    "                    print(\"\\nAudio Playback:\")\n",
    "                    print(\"Mix:\")\n",
    "                    display(Audio(mix.squeeze(0).cpu().numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean Speaker 1:\")\n",
    "                    display(Audio(clean[0].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean Speaker 2:\")\n",
    "                    display(Audio(clean[1].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimated Speaker 1:\")\n",
    "                    display(Audio(estimate[0, 0].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimated Speaker 2:\")\n",
    "                    display(Audio(estimate[0, 1].numpy(), rate=self.sample_rate))\n",
    "                else:\n",
    "                    print(\"\\nAudio Playback:\")\n",
    "                    print(\"Mix:\")\n",
    "                    display(Audio(mix.squeeze(0).cpu().numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean (Target):\")\n",
    "                    display(Audio(clean.squeeze(0).numpy() if clean.dim() > 1 else clean.numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimate (Output):\")\n",
    "                    display(Audio(estimate.squeeze(0).numpy(), rate=self.sample_rate))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error during testing: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    def _plot_waveforms(self, mix, clean, estimate):\n",
    "        \"\"\"Plot waveforms for comparison (enhancement tasks).\"\"\"\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 6), sharex=True)\n",
    "        \n",
    "        time = np.arange(len(mix)) / self.sample_rate\n",
    "        \n",
    "        axes[0].plot(time, mix.numpy(), linewidth=0.5)\n",
    "        axes[0].set_ylabel('Mix')\n",
    "        axes[0].set_title('Waveform Comparison')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1].plot(time, clean.numpy(), linewidth=0.5, color='green')\n",
    "        axes[1].set_ylabel('Clean (Target)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[2].plot(time, estimate.numpy(), linewidth=0.5, color='orange')\n",
    "        axes[2].set_ylabel('Estimate')\n",
    "        axes[2].set_xlabel('Time (s)')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_separation_waveforms(self, mix, clean, estimate):\n",
    "        \"\"\"Plot waveforms for speaker separation tasks.\"\"\"\n",
    "        fig, axes = plt.subplots(5, 1, figsize=(12, 10), sharex=True)\n",
    "        \n",
    "        time = np.arange(len(mix)) / self.sample_rate\n",
    "        \n",
    "        axes[0].plot(time, mix.numpy(), linewidth=0.5)\n",
    "        axes[0].set_ylabel('Mix')\n",
    "        axes[0].set_title('Speaker Separation Results')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1].plot(time, clean[0].numpy(), linewidth=0.5, color='green')\n",
    "        axes[1].set_ylabel('Clean Spk 1')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[2].plot(time, clean[1].numpy(), linewidth=0.5, color='darkgreen')\n",
    "        axes[2].set_ylabel('Clean Spk 2')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[3].plot(time, estimate[0].numpy(), linewidth=0.5, color='orange')\n",
    "        axes[3].set_ylabel('Est. Spk 1')\n",
    "        axes[3].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[4].plot(time, estimate[1].numpy(), linewidth=0.5, color='darkorange')\n",
    "        axes[4].set_ylabel('Est. Spk 2')\n",
    "        axes[4].set_xlabel('Time (s)')\n",
    "        axes[4].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the interactive UI.\"\"\"\n",
    "        # Layout\n",
    "        ui = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Model Testing Interface</h3>\"),\n",
    "            self.checkpoint_dropdown,\n",
    "            widgets.HBox([self.task_dropdown, self.variant_dropdown]),\n",
    "            self.sample_id_text,\n",
    "            self.show_plots_checkbox,\n",
    "            widgets.HBox([self.load_button, self.test_button]),\n",
    "            widgets.HTML(\"<hr>\"),\n",
    "            self.output\n",
    "        ])\n",
    "        \n",
    "        display(ui)\n",
    "\n",
    "# Create and display tester\n",
    "if available_checkpoints:\n",
    "    tester = ModelTester(available_checkpoints, DATA_ROOT, SAMPLE_RATE)\n",
    "    tester.display()\n",
    "else:\n",
    "    print(\"No checkpoints available. Please train a model first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
