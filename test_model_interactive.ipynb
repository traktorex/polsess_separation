{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Model Testing\n",
    "\n",
    "This notebook provides an interactive interface for testing trained speech separation models with dropdown widgets.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Auto-discovers available checkpoints from the hierarchical structure\n",
    "- Dropdown selectors for model, task, variant, and sample\n",
    "- Single-button model loading and testing\n",
    "- Audio playback and waveform visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/polsess_separation/venv/lib/python3.12/site-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "/home/user/polsess_separation/venv/lib/python3.12/site-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "/home/user/polsess_separation/venv/lib/python3.12/site-packages/torchmetrics/utilities/imports.py:22: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from config import Config\n",
    "from models import get_model\n",
    "from datasets import get_dataset\n",
    "from torchmetrics.audio import ScaleInvariantSignalDistortionRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Checkpoint Discovery\n",
    "\n",
    "Scan the checkpoint directory structure to find all available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 checkpoint(s):\n",
      "  - dprnn/EB/latest\n",
      "  - dprnn/EB/run_2025-12-13_01-12-25\n",
      "  - dprnn/ES/latest\n",
      "  - dprnn/ES/run_2025-12-13_01-06-16\n",
      "  - dprnn/SB/latest\n",
      "  - dprnn/SB/run_2025-12-13_00-35-29\n",
      "  - sb_task/convtasnet/SB\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_06-54-19\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_21-49-17\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_23-14-48\n",
      "  - spmamba/SB/spmamba_sb_reduced\n"
     ]
    }
   ],
   "source": [
    "def discover_checkpoints(checkpoint_root='checkpoints'):\n",
    "    \"\"\"Discover all available checkpoints in hierarchical structure.\n",
    "    \n",
    "    Structure: checkpoints/{model_name}/{task}/{run_name}/best_model.pt\n",
    "    \n",
    "    Returns dict: {display_name: checkpoint_path}\n",
    "    \"\"\"\n",
    "    checkpoint_root = Path(checkpoint_root)\n",
    "    checkpoints = {}\n",
    "    \n",
    "    if not checkpoint_root.exists():\n",
    "        print(f\"Warning: Checkpoint directory {checkpoint_root} does not exist\")\n",
    "        return checkpoints\n",
    "    \n",
    "    def scan_for_checkpoints(base_path):\n",
    "        \"\"\"Recursively scan for checkpoint files.\"\"\"\n",
    "        for item in base_path.iterdir():\n",
    "            if not item.is_dir():\n",
    "                continue\n",
    "            \n",
    "            # Check if this is a checkpoint file location\n",
    "            checkpoint_file = item / 'best_model.pt'\n",
    "            if checkpoint_file.exists():\n",
    "                # This is a run directory, extract info from path\n",
    "                path_parts = item.relative_to(checkpoint_root).parts\n",
    "                \n",
    "                # Expected structure: model_name/task/run_name\n",
    "                if len(path_parts) >= 3:\n",
    "                    model_name = path_parts[0]\n",
    "                    task = path_parts[1]\n",
    "                    run_name = path_parts[2]\n",
    "                    \n",
    "                    display_name = f\"{model_name}/{task}/{run_name}\"\n",
    "                    checkpoints[display_name] = str(checkpoint_file)\n",
    "            else:\n",
    "                # Recurse into subdirectories\n",
    "                scan_for_checkpoints(item)\n",
    "    \n",
    "    # Start scanning\n",
    "    scan_for_checkpoints(checkpoint_root)\n",
    "    \n",
    "    return checkpoints\n",
    "\n",
    "# Discover available checkpoints\n",
    "available_checkpoints = discover_checkpoints()\n",
    "\n",
    "if available_checkpoints:\n",
    "    print(f\"Found {len(available_checkpoints)} checkpoint(s):\")\n",
    "    for name in sorted(available_checkpoints.keys()):\n",
    "        print(f\"  - {name}\")\n",
    "else:\n",
    "    print(\"No checkpoints found. Train a model first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up dataset paths and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset path from config.py: /home/user/datasets/PolSESS_C_both/PolSESS_C_both\n",
      "Configuration loaded.\n",
      "Sample rate: 8000 Hz\n",
      "✓ Dataset path verified: /home/user/datasets/PolSESS_C_both/PolSESS_C_both\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "# Try to get data root from config.py defaults, or use manual override\n",
    "try:\n",
    "    from config import DataConfig\n",
    "    config_defaults = DataConfig()\n",
    "    DATA_ROOT = Path(config_defaults.polsess.data_root)\n",
    "    print(f\"Using dataset path from config.py: {DATA_ROOT}\")\n",
    "except Exception as e:\n",
    "    # Fallback: User can manually set the path here\n",
    "    DATA_ROOT = Path(\"F:/PolSMSE/EksperymentyMOWA/BAZY/MOWA/PolSESS_C_both/PolSESS_C_both\")\n",
    "    print(f\"Using manual dataset path: {DATA_ROOT}\")\n",
    "    print(f\"(Could not load from config: {e})\")\n",
    "\n",
    "SAMPLE_RATE = 8000\n",
    "\n",
    "# Available variants for PolSESS\n",
    "VARIANTS = {\n",
    "    'C': 'Clean (no background)',\n",
    "    'S': 'Scene only',\n",
    "    'E': 'Event only',\n",
    "    'R': 'Reverb only',\n",
    "    'SE': 'Scene + Event',\n",
    "    'SR': 'Scene + Reverb',\n",
    "    'ER': 'Event + Reverb',\n",
    "    'SER': 'Scene + Event + Reverb'\n",
    "}\n",
    "\n",
    "# Tasks\n",
    "TASKS = {\n",
    "    'ES': 'Enhance Single speaker',\n",
    "    'EB': 'Enhance Both speakers',\n",
    "    'SB': 'Separate Both speakers'\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"Sample rate: {SAMPLE_RATE} Hz\")\n",
    "\n",
    "# Verify dataset path exists\n",
    "if not DATA_ROOT.exists():\n",
    "    print(f\"\\n⚠️  WARNING: Dataset path does not exist: {DATA_ROOT}\")\n",
    "    print(\"Please update DATA_ROOT in this cell to point to your PolSESS dataset\")\n",
    "else:\n",
    "    print(f\"✓ Dataset path verified: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Model Testing\n",
    "\n",
    "Use dropdown widgets to select model, task, variant, and sample, then test the model with a single button click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7158e0b59cd546bfb0219ed1d08ec175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Model Testing Interface</h3>'), Dropdown(description='Checkpoint:', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ModelTester:\n",
    "    \"\"\"Interactive model testing with dropdown widgets.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoints, data_root, sample_rate=16000):\n",
    "        self.checkpoints = checkpoints\n",
    "        self.data_root = Path(data_root)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.model = None\n",
    "        self.config = None\n",
    "        self.dataset = None\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Create widgets\n",
    "        self.checkpoint_dropdown = widgets.Dropdown(\n",
    "            options=sorted(checkpoints.keys()),\n",
    "            description='Checkpoint:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='600px')\n",
    "        )\n",
    "        \n",
    "        self.task_dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{k}: {v}\", k) for k, v in TASKS.items()],\n",
    "            description='Task:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        self.variant_dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{k}: {v}\", k) for k, v in VARIANTS.items()],\n",
    "            description='Variant:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        self.sample_id_text = widgets.IntText(\n",
    "            value=0,\n",
    "            description='Sample ID:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        self.show_plots_checkbox = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Show waveform plots',\n",
    "            style={'description_width': '1px'},\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        self.load_button = widgets.Button(\n",
    "            description='Load Model',\n",
    "            button_style='info',\n",
    "            icon='download',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        self.test_button = widgets.Button(\n",
    "            description='Test Model',\n",
    "            button_style='success',\n",
    "            icon='play',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Button callbacks\n",
    "        self.load_button.on_click(self._on_load_clicked)\n",
    "        self.test_button.on_click(self._on_test_clicked)\n",
    "        \n",
    "        # Initially disable test button\n",
    "        self.test_button.disabled = True\n",
    "    \n",
    "    def _compute_pit_siSDR(self, estimate, clean, si_sdr_metric):\n",
    "        \"\"\"Compute permutation-invariant SI-SDR for speaker separation.\n",
    "        \n",
    "        Args:\n",
    "            estimate: [1, 2, T] - estimated speaker signals\n",
    "            clean: [2, T] - ground truth speaker signals\n",
    "            si_sdr_metric: SI-SDR metric function\n",
    "            \n",
    "        Returns:\n",
    "            best_sisdr_avg: Average SI-SDR for best permutation\n",
    "            best_sisdr1: SI-SDR for first speaker in best permutation\n",
    "            best_sisdr2: SI-SDR for second speaker in best permutation\n",
    "            best_perm: Best permutation index (0 or 1)\n",
    "        \"\"\"\n",
    "        # Permutation 1: est[0]->clean[0], est[1]->clean[1]\n",
    "        sisdr_perm1_spk1 = si_sdr_metric(estimate[:, 0:1, :], clean[0:1].unsqueeze(0))\n",
    "        sisdr_perm1_spk2 = si_sdr_metric(estimate[:, 1:2, :], clean[1:2].unsqueeze(0))\n",
    "        sisdr_perm1_avg = (sisdr_perm1_spk1 + sisdr_perm1_spk2) / 2\n",
    "        \n",
    "        # Permutation 2: est[0]->clean[1], est[1]->clean[0]\n",
    "        sisdr_perm2_spk1 = si_sdr_metric(estimate[:, 0:1, :], clean[1:2].unsqueeze(0))\n",
    "        sisdr_perm2_spk2 = si_sdr_metric(estimate[:, 1:2, :], clean[0:1].unsqueeze(0))\n",
    "        sisdr_perm2_avg = (sisdr_perm2_spk1 + sisdr_perm2_spk2) / 2\n",
    "        \n",
    "        # Choose best permutation\n",
    "        if sisdr_perm1_avg >= sisdr_perm2_avg:\n",
    "            return sisdr_perm1_avg, sisdr_perm1_spk1, sisdr_perm1_spk2, 0\n",
    "        else:\n",
    "            return sisdr_perm2_avg, sisdr_perm2_spk1, sisdr_perm2_spk2, 1\n",
    "    \n",
    "    def _on_load_clicked(self, b):\n",
    "        \"\"\"Load selected model checkpoint.\"\"\"\n",
    "        with self.output:\n",
    "            self.output.clear_output()\n",
    "            print(\"Loading model...\")\n",
    "            \n",
    "            try:\n",
    "                checkpoint_path = self.checkpoints[self.checkpoint_dropdown.value]\n",
    "                checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "                \n",
    "                # Load config from checkpoint\n",
    "                config_dict = checkpoint.get('config', {})\n",
    "                \n",
    "                # Also try loading config.yaml if available\n",
    "                config_yaml_path = Path(checkpoint_path).parent / 'config.yaml'\n",
    "                if config_yaml_path.exists():\n",
    "                    with open(config_yaml_path, 'r') as f:\n",
    "                        config_dict = yaml.safe_load(f)\n",
    "                \n",
    "                # Create config object\n",
    "                from types import SimpleNamespace\n",
    "                \n",
    "                def dict_to_namespace(d):\n",
    "                    if isinstance(d, dict):\n",
    "                        return SimpleNamespace(**{k: dict_to_namespace(v) for k, v in d.items()})\n",
    "                    return d\n",
    "                \n",
    "                self.config = dict_to_namespace(config_dict)\n",
    "                \n",
    "                # Get model class and create instance\n",
    "                model_type = self.config.model.model_type\n",
    "                ModelClass = get_model(model_type)\n",
    "                \n",
    "                # Get model-specific params\n",
    "                model_params = getattr(self.config.model, model_type, {})\n",
    "                if hasattr(model_params, '__dict__'):\n",
    "                    model_kwargs = vars(model_params)\n",
    "                else:\n",
    "                    model_kwargs = {}\n",
    "                \n",
    "                # Create model\n",
    "                self.model = ModelClass(**model_kwargs)\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                self.model.to(self.device)\n",
    "                self.model.eval()\n",
    "                \n",
    "                print(f\"✓ Model loaded: {model_type}\")\n",
    "                print(f\"  Checkpoint: {checkpoint_path}\")\n",
    "                print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "                print(f\"  Val SI-SDR: {checkpoint.get('val_sisdr', 'N/A'):.2f} dB\")\n",
    "                print(f\"  Device: {self.device}\")\n",
    "                \n",
    "                # Enable test button\n",
    "                self.test_button.disabled = False\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error loading model: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                self.test_button.disabled = True\n",
    "    \n",
    "    def _on_test_clicked(self, b):\n",
    "        \"\"\"Test model on selected sample.\"\"\"\n",
    "        with self.output:\n",
    "            self.output.clear_output(wait=True)\n",
    "            print(\"Testing model...\")\n",
    "            \n",
    "            try:\n",
    "                task = self.task_dropdown.value\n",
    "                variant = self.variant_dropdown.value\n",
    "                sample_id = self.sample_id_text.value\n",
    "                \n",
    "                # Create dataset\n",
    "                DatasetClass = get_dataset('polsess')\n",
    "                dataset = DatasetClass(\n",
    "                    data_root=str(self.data_root),\n",
    "                    subset='test',\n",
    "                    task=task,\n",
    "                    allowed_variants=[variant]\n",
    "                )\n",
    "                \n",
    "                if sample_id >= len(dataset):\n",
    "                    print(f\"✗ Error: Sample ID {sample_id} out of range (max: {len(dataset)-1})\")\n",
    "                    return\n",
    "                \n",
    "                # Get sample\n",
    "                sample = dataset[sample_id]\n",
    "                mix = sample['mix'].unsqueeze(0).to(self.device)  # [1, T]\n",
    "                clean = sample['clean']  # [C, T] where C is num speakers (1 or 2)\n",
    "                \n",
    "                # Handle different task types\n",
    "                is_separation = task == 'SB'  # Separate Both speakers\n",
    "                \n",
    "                # Run inference\n",
    "                with torch.no_grad():\n",
    "                    mix_input = mix.unsqueeze(1)  # [1, 1, T]\n",
    "                    estimate = self.model(mix_input)  # [1, C, T] for separation, [1, T] for enhancement\n",
    "                    estimate = estimate.cpu()\n",
    "                \n",
    "                # Compute SI-SDR based on task type\n",
    "                si_sdr_metric = ScaleInvariantSignalDistortionRatio()\n",
    "                \n",
    "                if is_separation:\n",
    "                    # For separation: use permutation-invariant SI-SDR\n",
    "                    if estimate.dim() == 3:  # [1, 2, T]\n",
    "                        # Compute PIT SI-SDR\n",
    "                        sisdr_avg, sisdr_spk1, sisdr_spk2, best_perm = self._compute_pit_siSDR(\n",
    "                            estimate, clean, si_sdr_metric\n",
    "                        )\n",
    "                        \n",
    "                        print(\"\\n\" + \"=\"*60)\n",
    "                        print(f\"Task: {task} | Variant: {variant} | Sample: {sample_id}\")\n",
    "                        print(\"=\"*60)\n",
    "                        print(f\"SI-SDR (Speaker 1):     {sisdr_spk1.item():>8.2f} dB\")\n",
    "                        print(f\"SI-SDR (Speaker 2):     {sisdr_spk2.item():>8.2f} dB\")\n",
    "                        print(f\"SI-SDR (Average):       {sisdr_avg.item():>8.2f} dB\")\n",
    "                        if best_perm == 1:\n",
    "                            print(f\"Note: Best permutation swapped speaker order\")\n",
    "                        print(\"=\"*60 + \"\\n\")\n",
    "                    else:\n",
    "                        raise ValueError(f\"Expected 3D output [1, 2, T] for separation, got {estimate.shape}\")\n",
    "                else:\n",
    "                    # For enhancement: clean is [T], estimate is [1, T]\n",
    "                    if clean.dim() > 1:\n",
    "                        clean = clean[0]  # Take first speaker if multi-channel\n",
    "                    \n",
    "                    si_sdr_mix = si_sdr_metric(mix.cpu(), clean.unsqueeze(0))\n",
    "                    si_sdr_estimate = si_sdr_metric(estimate, clean.unsqueeze(0))\n",
    "                    improvement = si_sdr_estimate - si_sdr_mix\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(f\"Task: {task} | Variant: {variant} | Sample: {sample_id}\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"SI-SDR (Mix):      {si_sdr_mix.item():>8.2f} dB\")\n",
    "                    print(f\"SI-SDR (Estimate): {si_sdr_estimate.item():>8.2f} dB\")\n",
    "                    print(f\"Improvement:       {improvement.item():>8.2f} dB\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                \n",
    "                # Visualize waveforms (only if checkbox is checked)\n",
    "                if self.show_plots_checkbox.value:\n",
    "                    if is_separation and estimate.dim() == 3:\n",
    "                        self._plot_separation_waveforms(\n",
    "                            mix.squeeze(0).cpu(),\n",
    "                            clean,\n",
    "                            estimate.squeeze(0)  # [2, T]\n",
    "                        )\n",
    "                    else:\n",
    "                        self._plot_waveforms(\n",
    "                            mix.squeeze(0).cpu(),\n",
    "                            clean.squeeze(0) if clean.dim() > 1 else clean,\n",
    "                            estimate.squeeze(0)\n",
    "                        )\n",
    "                \n",
    "                # Audio playback\n",
    "                if is_separation:\n",
    "                    print(\"\\nAudio Playback:\")\n",
    "                    print(\"Mix:\")\n",
    "                    display(Audio(mix.squeeze(0).cpu().numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean Speaker 1:\")\n",
    "                    display(Audio(clean[0].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean Speaker 2:\")\n",
    "                    display(Audio(clean[1].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimated Speaker 1:\")\n",
    "                    display(Audio(estimate[0, 0].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimated Speaker 2:\")\n",
    "                    display(Audio(estimate[0, 1].numpy(), rate=self.sample_rate))\n",
    "                else:\n",
    "                    print(\"\\nAudio Playback:\")\n",
    "                    print(\"Mix:\")\n",
    "                    display(Audio(mix.squeeze(0).cpu().numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean (Target):\")\n",
    "                    display(Audio(clean.squeeze(0).numpy() if clean.dim() > 1 else clean.numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimate (Output):\")\n",
    "                    display(Audio(estimate.squeeze(0).numpy(), rate=self.sample_rate))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error during testing: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    def _plot_waveforms(self, mix, clean, estimate):\n",
    "        \"\"\"Plot waveforms for comparison (enhancement tasks).\"\"\"\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 6), sharex=True)\n",
    "        \n",
    "        time = np.arange(len(mix)) / self.sample_rate\n",
    "        \n",
    "        axes[0].plot(time, mix.numpy(), linewidth=0.5)\n",
    "        axes[0].set_ylabel('Mix')\n",
    "        axes[0].set_title('Waveform Comparison')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1].plot(time, clean.numpy(), linewidth=0.5, color='green')\n",
    "        axes[1].set_ylabel('Clean (Target)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[2].plot(time, estimate.numpy(), linewidth=0.5, color='orange')\n",
    "        axes[2].set_ylabel('Estimate')\n",
    "        axes[2].set_xlabel('Time (s)')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_separation_waveforms(self, mix, clean, estimate):\n",
    "        \"\"\"Plot waveforms for speaker separation tasks.\"\"\"\n",
    "        fig, axes = plt.subplots(5, 1, figsize=(12, 10), sharex=True)\n",
    "        \n",
    "        time = np.arange(len(mix)) / self.sample_rate\n",
    "        \n",
    "        axes[0].plot(time, mix.numpy(), linewidth=0.5)\n",
    "        axes[0].set_ylabel('Mix')\n",
    "        axes[0].set_title('Speaker Separation Results')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1].plot(time, clean[0].numpy(), linewidth=0.5, color='green')\n",
    "        axes[1].set_ylabel('Clean Spk 1')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[2].plot(time, clean[1].numpy(), linewidth=0.5, color='darkgreen')\n",
    "        axes[2].set_ylabel('Clean Spk 2')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[3].plot(time, estimate[0].numpy(), linewidth=0.5, color='orange')\n",
    "        axes[3].set_ylabel('Est. Spk 1')\n",
    "        axes[3].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[4].plot(time, estimate[1].numpy(), linewidth=0.5, color='darkorange')\n",
    "        axes[4].set_ylabel('Est. Spk 2')\n",
    "        axes[4].set_xlabel('Time (s)')\n",
    "        axes[4].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the interactive UI.\"\"\"\n",
    "        # Layout\n",
    "        ui = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Model Testing Interface</h3>\"),\n",
    "            self.checkpoint_dropdown,\n",
    "            widgets.HBox([self.task_dropdown, self.variant_dropdown]),\n",
    "            self.sample_id_text,\n",
    "            self.show_plots_checkbox,\n",
    "            widgets.HBox([self.load_button, self.test_button]),\n",
    "            widgets.HTML(\"<hr>\"),\n",
    "            self.output\n",
    "        ])\n",
    "        \n",
    "        display(ui)\n",
    "\n",
    "# Create and display tester\n",
    "if available_checkpoints:\n",
    "    tester = ModelTester(available_checkpoints, DATA_ROOT, SAMPLE_RATE)\n",
    "    tester.display()\n",
    "else:\n",
    "    print(\"No checkpoints available. Please train a model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. **Select Checkpoint**: Choose a trained model from the dropdown\n",
    "2. **Click Load Model**: Loads the model and displays configuration info\n",
    "3. **Configure Test**: Select task, variant, and sample ID\n",
    "4. **Click Test Model**: Runs inference and displays:\n",
    "   - SI-SDR metrics (mix, estimate, improvement)\n",
    "   - Waveform comparison plots\n",
    "   - Audio playback for mix, clean, and estimate\n",
    "\n",
    "## Tips\n",
    "\n",
    "- Start with sample_id=0 and explore different samples\n",
    "- Compare different variants (C, S, E, R, SE, SR, ER, SER) to see model robustness\n",
    "- SI-SDR improvement > 0 dB indicates successful separation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
