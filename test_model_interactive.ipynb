{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Model Testing\n",
    "\n",
    "This notebook provides an interactive interface for testing trained speech separation models with dropdown widgets.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Auto-discovers available checkpoints from the new hierarchical structure\n",
    "- Dropdown selectors for model, task, variant, and sample\n",
    "- Recognizes 'latest' symlinks for easy access\n",
    "- Single-button model loading and testing\n",
    "- Audio playback and waveform visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from config import Config\n",
    "from models import get_model\n",
    "from datasets import get_dataset\n",
    "from torchmetrics.audio import ScaleInvariantSignalDistortionRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Checkpoint Discovery\n",
    "\n",
    "Scan the checkpoint directory structure to find all available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 checkpoint(s):\n",
      "  - dprnn/EB/[LATEST]\n",
      "  - dprnn/EB/run_2025-12-13_01-08-35\n",
      "  - dprnn/EB/run_2025-12-13_01-09-50\n",
      "  - dprnn/EB/run_2025-12-13_01-11-09\n",
      "  - dprnn/EB/run_2025-12-13_01-12-25\n",
      "  - dprnn/ES/[LATEST]\n",
      "  - dprnn/ES/run_2025-12-13_01-01-13\n",
      "  - dprnn/ES/run_2025-12-13_01-02-30\n",
      "  - dprnn/ES/run_2025-12-13_01-03-45\n",
      "  - dprnn/ES/run_2025-12-13_01-06-16\n",
      "  - dprnn/SB/[LATEST]\n",
      "  - dprnn/SB/run_2025-12-12_22-47-32\n",
      "  - dprnn/SB/run_2025-12-12_22-50-04\n",
      "  - dprnn/SB/run_2025-12-12_22-52-34\n",
      "  - dprnn/SB/run_2025-12-12_22-57-38\n",
      "  - dprnn/SB/run_2025-12-12_23-00-09\n",
      "  - dprnn/SB/run_2025-12-12_23-02-42\n",
      "  - dprnn/SB/run_2025-12-12_23-05-13\n",
      "  - dprnn/SB/run_2025-12-12_23-07-50\n",
      "  - dprnn/SB/run_2025-12-12_23-10-30\n",
      "  - dprnn/SB/run_2025-12-12_23-13-08\n",
      "  - dprnn/SB/run_2025-12-12_23-15-48\n",
      "  - dprnn/SB/run_2025-12-12_23-18-28\n",
      "  - dprnn/SB/run_2025-12-12_23-21-03\n",
      "  - dprnn/SB/run_2025-12-12_23-26-16\n",
      "  - dprnn/SB/run_2025-12-12_23-28-52\n",
      "  - dprnn/SB/run_2025-12-12_23-34-14\n",
      "  - dprnn/SB/run_2025-12-12_23-39-31\n",
      "  - dprnn/SB/run_2025-12-12_23-42-12\n",
      "  - dprnn/SB/run_2025-12-12_23-47-28\n",
      "  - dprnn/SB/run_2025-12-12_23-52-48\n",
      "  - dprnn/SB/run_2025-12-12_23-58-05\n",
      "  - dprnn/SB/run_2025-12-13_00-11-12\n",
      "  - dprnn/SB/run_2025-12-13_00-24-30\n",
      "  - dprnn/SB/run_2025-12-13_00-35-29\n",
      "  - spmamba/SB/[LATEST]\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_02-04-43\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_06-54-19\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_16-06-35\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_17-32-35\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_18-58-11\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_20-23-45\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_21-49-17\n",
      "  - spmamba/SB/spmamba_sb_baseline_2025-12-13_23-14-48\n"
     ]
    }
   ],
   "source": [
    "def discover_checkpoints(checkpoint_root='checkpoints'):\n",
    "    \"\"\"Discover all available checkpoints in hierarchical structure.\n",
    "    \n",
    "    Supports both patterns:\n",
    "    - Standard: checkpoints/{model}/{task}/{run_id}/best_model.pt\n",
    "    - Legacy/misconfigured: checkpoints/{model}/{model}/{task}/{run_id}/best_model.pt\n",
    "    \n",
    "    Returns dict: {display_name: checkpoint_path}\n",
    "    \"\"\"\n",
    "    checkpoint_root = Path(checkpoint_root)\n",
    "    checkpoints = {}\n",
    "    \n",
    "    if not checkpoint_root.exists():\n",
    "        print(f\"Warning: Checkpoint directory {checkpoint_root} does not exist\")\n",
    "        return checkpoints\n",
    "    \n",
    "    def scan_for_checkpoints(base_path, model_type_prefix=\"\"):\n",
    "        \"\"\"Recursively scan for checkpoint files.\"\"\"\n",
    "        for item in base_path.iterdir():\n",
    "            if not item.is_dir():\n",
    "                continue\n",
    "            \n",
    "            # Check if this is a checkpoint file location\n",
    "            checkpoint_file = item / 'best_model.pt'\n",
    "            if checkpoint_file.exists():\n",
    "                # This is a run directory, extract info from path\n",
    "                path_parts = item.relative_to(checkpoint_root).parts\n",
    "                \n",
    "                # Handle both structures:\n",
    "                # Standard: model/task/run_id\n",
    "                # Legacy: model/model/task/run_id\n",
    "                if len(path_parts) >= 3:\n",
    "                    if path_parts[0] == path_parts[1]:\n",
    "                        # Legacy structure: model/model/task/run_id\n",
    "                        model_type = path_parts[0]\n",
    "                        task = path_parts[2]\n",
    "                        run_id = path_parts[3] if len(path_parts) > 3 else path_parts[2]\n",
    "                    else:\n",
    "                        # Standard structure: model/task/run_id\n",
    "                        model_type = path_parts[0]\n",
    "                        task = path_parts[1]\n",
    "                        run_id = path_parts[2] if len(path_parts) > 2 else path_parts[1]\n",
    "                    \n",
    "                    # Create display name\n",
    "                    if run_id == 'latest' or item.name == 'latest':\n",
    "                        display_name = f\"{model_type}/{task}/[LATEST]\"\n",
    "                    else:\n",
    "                        display_name = f\"{model_type}/{task}/{run_id}\"\n",
    "                    \n",
    "                    checkpoints[display_name] = str(checkpoint_file)\n",
    "            else:\n",
    "                # Recurse into subdirectories\n",
    "                scan_for_checkpoints(item, model_type_prefix)\n",
    "    \n",
    "    # Start scanning\n",
    "    scan_for_checkpoints(checkpoint_root)\n",
    "    \n",
    "    return checkpoints\n",
    "\n",
    "# Discover available checkpoints\n",
    "available_checkpoints = discover_checkpoints()\n",
    "\n",
    "if available_checkpoints:\n",
    "    print(f\"Found {len(available_checkpoints)} checkpoint(s):\")\n",
    "    for name in sorted(available_checkpoints.keys()):\n",
    "        print(f\"  - {name}\")\n",
    "else:\n",
    "    print(\"No checkpoints found. Train a model first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up dataset paths and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset path from config.py: /home/user/datasets/PolSESS_C_both/PolSESS_C_both\n",
      "Configuration loaded.\n",
      "Sample rate: 8000 Hz\n",
      "✓ Dataset path verified: /home/user/datasets/PolSESS_C_both/PolSESS_C_both\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "# Try to get data root from config.py defaults, or use manual override\n",
    "try:\n",
    "    from config import DataConfig\n",
    "    config_defaults = DataConfig()\n",
    "    DATA_ROOT = Path(config_defaults.polsess.data_root)\n",
    "    print(f\"Using dataset path from config.py: {DATA_ROOT}\")\n",
    "except Exception as e:\n",
    "    # Fallback: User can manually set the path here\n",
    "    DATA_ROOT = Path(\"F:/PolSMSE/EksperymentyMOWA/BAZY/MOWA/PolSESS_C_both/PolSESS_C_both\")\n",
    "    print(f\"Using manual dataset path: {DATA_ROOT}\")\n",
    "    print(f\"(Could not load from config: {e})\")\n",
    "\n",
    "SAMPLE_RATE = 8000\n",
    "\n",
    "# Available variants for PolSESS\n",
    "VARIANTS = {\n",
    "    'C': 'Clean (no background)',\n",
    "    'S': 'Speech only',\n",
    "    'E': 'Event only',\n",
    "    'R': 'Reverb only',\n",
    "    'SE': 'Speech + Event',\n",
    "    'SR': 'Speech + Reverb',\n",
    "    'ER': 'Event + Reverb',\n",
    "    'SER': 'Speech + Event + Reverb'\n",
    "}\n",
    "\n",
    "# Tasks\n",
    "TASKS = {\n",
    "    'ES': 'Enhance Single speaker',\n",
    "    'EB': 'Enhance Both speakers',\n",
    "    'SB': 'Separate Both speakers'\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"Sample rate: {SAMPLE_RATE} Hz\")\n",
    "\n",
    "# Verify dataset path exists\n",
    "if not DATA_ROOT.exists():\n",
    "    print(f\"\\n⚠️  WARNING: Dataset path does not exist: {DATA_ROOT}\")\n",
    "    print(\"Please update DATA_ROOT in this cell to point to your PolSESS dataset\")\n",
    "else:\n",
    "    print(f\"✓ Dataset path verified: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Model Testing\n",
    "\n",
    "Use dropdown widgets to select model, task, variant, and sample, then test the model with a single button click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3a1495882e4254a089d03bf3e24a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Model Testing Interface</h3>'), Dropdown(description='Checkpoint:', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ModelTester:\n",
    "    \"\"\"Interactive model testing with dropdown widgets.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoints, data_root, sample_rate=16000):\n",
    "        self.checkpoints = checkpoints\n",
    "        self.data_root = Path(data_root)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.model = None\n",
    "        self.config = None\n",
    "        self.dataset = None\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Create widgets\n",
    "        self.checkpoint_dropdown = widgets.Dropdown(\n",
    "            options=sorted(checkpoints.keys()),\n",
    "            description='Checkpoint:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='600px')\n",
    "        )\n",
    "        \n",
    "        self.task_dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{k}: {v}\", k) for k, v in TASKS.items()],\n",
    "            description='Task:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        self.variant_dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{k}: {v}\", k) for k, v in VARIANTS.items()],\n",
    "            description='Variant:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        self.sample_id_text = widgets.IntText(\n",
    "            value=0,\n",
    "            description='Sample ID:',\n",
    "            style={'description_width': '120px'},\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        self.load_button = widgets.Button(\n",
    "            description='Load Model',\n",
    "            button_style='info',\n",
    "            icon='download',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        self.test_button = widgets.Button(\n",
    "            description='Test Model',\n",
    "            button_style='success',\n",
    "            icon='play',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Button callbacks\n",
    "        self.load_button.on_click(self._on_load_clicked)\n",
    "        self.test_button.on_click(self._on_test_clicked)\n",
    "        \n",
    "        # Initially disable test button\n",
    "        self.test_button.disabled = True\n",
    "    \n",
    "    def _on_load_clicked(self, b):\n",
    "        \"\"\"Load selected model checkpoint.\"\"\"\n",
    "        with self.output:\n",
    "            self.output.clear_output()\n",
    "            print(\"Loading model...\")\n",
    "            \n",
    "            try:\n",
    "                checkpoint_path = self.checkpoints[self.checkpoint_dropdown.value]\n",
    "                checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "                \n",
    "                # Load config from checkpoint\n",
    "                config_dict = checkpoint.get('config', {})\n",
    "                \n",
    "                # Also try loading config.yaml if available\n",
    "                config_yaml_path = Path(checkpoint_path).parent / 'config.yaml'\n",
    "                if config_yaml_path.exists():\n",
    "                    with open(config_yaml_path, 'r') as f:\n",
    "                        config_dict = yaml.safe_load(f)\n",
    "                \n",
    "                # Create config object\n",
    "                from types import SimpleNamespace\n",
    "                \n",
    "                def dict_to_namespace(d):\n",
    "                    if isinstance(d, dict):\n",
    "                        return SimpleNamespace(**{k: dict_to_namespace(v) for k, v in d.items()})\n",
    "                    return d\n",
    "                \n",
    "                self.config = dict_to_namespace(config_dict)\n",
    "                \n",
    "                # Get model class and create instance\n",
    "                model_type = self.config.model.model_type\n",
    "                ModelClass = get_model(model_type)\n",
    "                \n",
    "                # Get model-specific params\n",
    "                model_params = getattr(self.config.model, model_type, {})\n",
    "                if hasattr(model_params, '__dict__'):\n",
    "                    model_kwargs = vars(model_params)\n",
    "                else:\n",
    "                    model_kwargs = {}\n",
    "                \n",
    "                # Create model\n",
    "                self.model = ModelClass(**model_kwargs)\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                self.model.to(self.device)\n",
    "                self.model.eval()\n",
    "                \n",
    "                print(f\"✓ Model loaded: {model_type}\")\n",
    "                print(f\"  Checkpoint: {checkpoint_path}\")\n",
    "                print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "                print(f\"  Val SI-SDR: {checkpoint.get('val_sisdr', 'N/A'):.2f} dB\")\n",
    "                print(f\"  Device: {self.device}\")\n",
    "                \n",
    "                # Enable test button\n",
    "                self.test_button.disabled = False\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error loading model: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                self.test_button.disabled = True\n",
    "    \n",
    "    def _on_test_clicked(self, b):\n",
    "        \"\"\"Test model on selected sample.\"\"\"\n",
    "        with self.output:\n",
    "            self.output.clear_output(wait=True)\n",
    "            print(\"Testing model...\")\n",
    "            \n",
    "            try:\n",
    "                task = self.task_dropdown.value\n",
    "                variant = self.variant_dropdown.value\n",
    "                sample_id = self.sample_id_text.value\n",
    "                \n",
    "                # Create dataset\n",
    "                DatasetClass = get_dataset('polsess')\n",
    "                dataset = DatasetClass(\n",
    "                    data_root=str(self.data_root),\n",
    "                    subset='test',\n",
    "                    task=task,\n",
    "                    allowed_variants=[variant]\n",
    "                )\n",
    "                \n",
    "                if sample_id >= len(dataset):\n",
    "                    print(f\"✗ Error: Sample ID {sample_id} out of range (max: {len(dataset)-1})\")\n",
    "                    return\n",
    "                \n",
    "                # Get sample\n",
    "                sample = dataset[sample_id]\n",
    "                mix = sample['mix'].unsqueeze(0).to(self.device)  # [1, T]\n",
    "                clean = sample['clean']  # [C, T] where C is num speakers (1 or 2)\n",
    "                \n",
    "                # Handle different task types\n",
    "                is_separation = task == 'SB'  # Separate Both speakers\n",
    "                \n",
    "                # Run inference\n",
    "                with torch.no_grad():\n",
    "                    mix_input = mix.unsqueeze(1)  # [1, 1, T]\n",
    "                    estimate = self.model(mix_input)  # [1, C, T] for separation, [1, T] for enhancement\n",
    "                    estimate = estimate.cpu()\n",
    "                \n",
    "                # Compute SI-SDR based on task type\n",
    "                si_sdr_metric = ScaleInvariantSignalDistortionRatio()\n",
    "                \n",
    "                if is_separation:\n",
    "                    # For separation: clean is [2, T], estimate should be [1, 2, T]\n",
    "                    # Compare mix to sum of both speakers for baseline\n",
    "                    clean_sum = clean.sum(dim=0, keepdim=True)  # [1, T]\n",
    "                    si_sdr_mix = si_sdr_metric(mix.cpu(), clean_sum)\n",
    "                    \n",
    "                    # Compute SI-SDR for each separated speaker\n",
    "                    if estimate.dim() == 3:  # [1, 2, T]\n",
    "                        # Average SI-SDR across both speakers\n",
    "                        si_sdr_spk1 = si_sdr_metric(estimate[:, 0:1, :], clean[0:1].unsqueeze(0))\n",
    "                        si_sdr_spk2 = si_sdr_metric(estimate[:, 1:2, :], clean[1:2].unsqueeze(0))\n",
    "                        si_sdr_estimate = (si_sdr_spk1 + si_sdr_spk2) / 2\n",
    "                        \n",
    "                        print(\"\\n\" + \"=\"*60)\n",
    "                        print(f\"Task: {task} | Variant: {variant} | Sample: {sample_id}\")\n",
    "                        print(\"=\"*60)\n",
    "                        print(f\"SI-SDR (Mix):           {si_sdr_mix.item():>8.2f} dB\")\n",
    "                        print(f\"SI-SDR (Speaker 1):     {si_sdr_spk1.item():>8.2f} dB\")\n",
    "                        print(f\"SI-SDR (Speaker 2):     {si_sdr_spk2.item():>8.2f} dB\")\n",
    "                        print(f\"SI-SDR (Average):       {si_sdr_estimate.item():>8.2f} dB\")\n",
    "                        print(f\"Improvement (Avg):      {(si_sdr_estimate - si_sdr_mix).item():>8.2f} dB\")\n",
    "                        print(\"=\"*60 + \"\\n\")\n",
    "                    else:\n",
    "                        raise ValueError(f\"Expected 3D output [1, 2, T] for separation, got {estimate.shape}\")\n",
    "                else:\n",
    "                    # For enhancement: clean is [T], estimate is [1, T]\n",
    "                    if clean.dim() > 1:\n",
    "                        clean = clean[0]  # Take first speaker if multi-channel\n",
    "                    \n",
    "                    si_sdr_mix = si_sdr_metric(mix.cpu(), clean.unsqueeze(0))\n",
    "                    si_sdr_estimate = si_sdr_metric(estimate, clean.unsqueeze(0))\n",
    "                    improvement = si_sdr_estimate - si_sdr_mix\n",
    "                    \n",
    "                    print(\"\\n\" + \"=\"*60)\n",
    "                    print(f\"Task: {task} | Variant: {variant} | Sample: {sample_id}\")\n",
    "                    print(\"=\"*60)\n",
    "                    print(f\"SI-SDR (Mix):      {si_sdr_mix.item():>8.2f} dB\")\n",
    "                    print(f\"SI-SDR (Estimate): {si_sdr_estimate.item():>8.2f} dB\")\n",
    "                    print(f\"Improvement:       {improvement.item():>8.2f} dB\")\n",
    "                    print(\"=\"*60 + \"\\n\")\n",
    "                \n",
    "                # Visualize waveforms\n",
    "                if is_separation and estimate.dim() == 3:\n",
    "                    self._plot_separation_waveforms(\n",
    "                        mix.squeeze(0).cpu(),\n",
    "                        clean,\n",
    "                        estimate.squeeze(0)  # [2, T]\n",
    "                    )\n",
    "                    \n",
    "                    # Audio playback for separation\n",
    "                    print(\"\\nAudio Playback:\")\n",
    "                    print(\"Mix:\")\n",
    "                    display(Audio(mix.squeeze(0).cpu().numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean Speaker 1:\")\n",
    "                    display(Audio(clean[0].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean Speaker 2:\")\n",
    "                    display(Audio(clean[1].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimated Speaker 1:\")\n",
    "                    display(Audio(estimate[0, 0].numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimated Speaker 2:\")\n",
    "                    display(Audio(estimate[0, 1].numpy(), rate=self.sample_rate))\n",
    "                else:\n",
    "                    self._plot_waveforms(\n",
    "                        mix.squeeze(0).cpu(),\n",
    "                        clean.squeeze(0) if clean.dim() > 1 else clean,\n",
    "                        estimate.squeeze(0)\n",
    "                    )\n",
    "                    \n",
    "                    # Audio playback for enhancement\n",
    "                    print(\"\\nAudio Playback:\")\n",
    "                    print(\"Mix:\")\n",
    "                    display(Audio(mix.squeeze(0).cpu().numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nClean (Target):\")\n",
    "                    display(Audio(clean.squeeze(0).numpy() if clean.dim() > 1 else clean.numpy(), rate=self.sample_rate))\n",
    "                    print(\"\\nEstimate (Output):\")\n",
    "                    display(Audio(estimate.squeeze(0).numpy(), rate=self.sample_rate))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error during testing: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    def _plot_waveforms(self, mix, clean, estimate):\n",
    "        \"\"\"Plot waveforms for comparison (enhancement tasks).\"\"\"\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 6), sharex=True)\n",
    "        \n",
    "        time = np.arange(len(mix)) / self.sample_rate\n",
    "        \n",
    "        axes[0].plot(time, mix.numpy(), linewidth=0.5)\n",
    "        axes[0].set_ylabel('Mix')\n",
    "        axes[0].set_title('Waveform Comparison')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1].plot(time, clean.numpy(), linewidth=0.5, color='green')\n",
    "        axes[1].set_ylabel('Clean (Target)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[2].plot(time, estimate.numpy(), linewidth=0.5, color='orange')\n",
    "        axes[2].set_ylabel('Estimate')\n",
    "        axes[2].set_xlabel('Time (s)')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_separation_waveforms(self, mix, clean, estimate):\n",
    "        \"\"\"Plot waveforms for speaker separation tasks.\"\"\"\n",
    "        fig, axes = plt.subplots(5, 1, figsize=(12, 10), sharex=True)\n",
    "        \n",
    "        time = np.arange(len(mix)) / self.sample_rate\n",
    "        \n",
    "        axes[0].plot(time, mix.numpy(), linewidth=0.5)\n",
    "        axes[0].set_ylabel('Mix')\n",
    "        axes[0].set_title('Speaker Separation Results')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1].plot(time, clean[0].numpy(), linewidth=0.5, color='green')\n",
    "        axes[1].set_ylabel('Clean Spk 1')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[2].plot(time, clean[1].numpy(), linewidth=0.5, color='darkgreen')\n",
    "        axes[2].set_ylabel('Clean Spk 2')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[3].plot(time, estimate[0].numpy(), linewidth=0.5, color='orange')\n",
    "        axes[3].set_ylabel('Est. Spk 1')\n",
    "        axes[3].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[4].plot(time, estimate[1].numpy(), linewidth=0.5, color='darkorange')\n",
    "        axes[4].set_ylabel('Est. Spk 2')\n",
    "        axes[4].set_xlabel('Time (s)')\n",
    "        axes[4].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the interactive UI.\"\"\"\n",
    "        # Layout\n",
    "        ui = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Model Testing Interface</h3>\"),\n",
    "            self.checkpoint_dropdown,\n",
    "            widgets.HBox([self.task_dropdown, self.variant_dropdown]),\n",
    "            self.sample_id_text,\n",
    "            widgets.HBox([self.load_button, self.test_button]),\n",
    "            widgets.HTML(\"<hr>\"),\n",
    "            self.output\n",
    "        ])\n",
    "        \n",
    "        display(ui)\n",
    "\n",
    "# Create and display tester\n",
    "if available_checkpoints:\n",
    "    tester = ModelTester(available_checkpoints, DATA_ROOT, SAMPLE_RATE)\n",
    "    tester.display()\n",
    "else:\n",
    "    print(\"No checkpoints available. Please train a model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. **Select Checkpoint**: Choose a trained model from the dropdown (use `[LATEST]` for most recent)\n",
    "2. **Click Load Model**: Loads the model and displays configuration info\n",
    "3. **Configure Test**: Select task, variant, and sample ID\n",
    "4. **Click Test Model**: Runs inference and displays:\n",
    "   - SI-SDR metrics (mix, estimate, improvement)\n",
    "   - Waveform comparison plots\n",
    "   - Audio playback for mix, clean, and estimate\n",
    "\n",
    "## Tips\n",
    "\n",
    "- Use the `latest` symlink to always test the most recent model\n",
    "- Start with sample_id=0 and explore different samples\n",
    "- Compare different variants (C, S, E, R, SE, SR, ER, SER) to see model robustness\n",
    "- SI-SDR improvement > 0 dB indicates successful separation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
