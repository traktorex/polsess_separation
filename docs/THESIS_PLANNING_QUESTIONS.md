# Master's Thesis Planning Questions

**Purpose**: Strategic thinking before committing to project architecture
**Date**: 2025-11-29
**Status**: In Progress

---

## Your Answers So Far

### Research Direction
**Focus Areas**:
- Comparison of model architectures and their efficiency in different scenarios
  - Deployment considerations (websites, mobile apps)
  - Parameter count vs. performance trade-offs
- End-to-end vs. modular networks comparison
  - Single multi-task model (enhancement + separation) vs. pipeline approach
  - Multi-task learning investigation
- Context: Noisy speech dataset with sound events AND reverberation
- **NOT focusing on**: Specific applications (hearing aids, voice assistants)
- **Focus on**: Technology and science
- **Interest**: Transfer learning across datasets, possibly foundational models

### Novelty & Contribution
- **No new model architectures** (too much for master's thesis)
- Adapt existing models to Polish language datasets (nature currently unknown)
- **Definite**: MM-IPC experiments
- **Tool Development**: Research-focused, not commercial product
  - But closer to "training app" than originally planned
  - Clarity needed on scope

### Scope Boundaries
- Number of experiments: Unknown yet
- **Ablation studies**: New to you, seems interesting
- **Cross-dataset evaluation**: Definitely yes
  - Train on X, test on Y
  - Use PESQ and other metrics beyond SI-SDR
- **Ensemble methods**: Interesting but probably too much

### Dataset Requirements
**Confirmed Datasets**:
1. PolSESS
2. LibriMix
3. One other (currently unspecified)

**Constraints**:
- **Sample rate**: 8kHz only (simplification)
- **Speakers**: 2 speakers only (simplification)

**Augmentation**:
- New dataset will probably need augmentation
- Should be implemented within dataset class file
- Should NOT affect rest of project (modularity)

---

## Your Key Concerns

### Architecture Philosophy
- Want modularity without bloat
- Code should demonstrate process and ideas
- **NOT** building a ready-to-ship commercial product
- Clean and readable FIRST
- Questioning whether trainer_factory is necessary
- Avoid convolution and bloat

### Current Uncertainties
- Exact number of experiments
- Nature of new Polish datasets (will clarify thesis scope)
- Thesis statement (will come later)
- Many answers will emerge during thesis work

---

## Complete Question Set

### ğŸ¯ Thesis Scope & Research Questions

#### 1. Research Direction
- What general area of speech separation interests you most?
  - Model architecture comparisons? âœ“
  - Dataset-specific challenges (low-resource languages, reverberant conditions)? âœ“
  - Practical applications (hearing aids, voice assistants)? âœ—
  - Transfer learning across datasets? âœ“ (very interesting)
  - Efficiency vs. performance trade-offs? âœ“

#### 2. Novelty & Contribution
- Are you planning to:
  - Propose a new model architecture? âœ—
  - Adapt existing models to a new problem (e.g., Polish language specificity)? âœ“
  - Conduct comprehensive benchmarking/comparison studies? âœ“
  - Investigate a specific phenomenon (e.g., multi-modal corpus augmentation like MM-IPC)? âœ“
  - Develop practical tools/frameworks? ~ (research tool, not commercial)

#### 3. Scope Boundaries
- How many experiments do you envision running? (10? 50? 100?) â†’ Unknown
- Will you need to run ablation studies (varying single parameters)? â†’ Interesting, new to you
- Do you plan to do cross-dataset evaluation (train on A, test on B)? â†’ âœ“ Definitely
- Will you need ensemble methods or model combinations? â†’ Interesting but probably too much

---

### ğŸ“Š Dataset Requirements

#### 4. Dataset Diversity
- Beyond PolSESS, which datasets are you considering?
  - WSJ0-2Mix/3Mix (English, standard benchmark)? â†’ No
  - LibriMix (modern, larger scale)? â†’ âœ“
  - WHAM!/WHAMR! (with noise/reverb)? â†’ No
  - DNS Challenge (Microsoft, diverse noise)? â†’ No
  - Language-specific datasets (Polish, others)? â†’ âœ“ (one more, unspecified)
  - Custom datasets you'll create? â†’ Unknown

#### 5. Dataset Characteristics âœ“ ANSWERED
- What variations do you need to handle?
  - Sample rates: 8kHz only âœ“
  - Number of speakers: 2 only âœ“
  - Background conditions: clean, noisy, reverberant â†’ noisy + reverberant âœ“
  - Recording conditions: indoor, outdoor, multi-modal â†’ Unknown
  - Languages: monolingual vs. multilingual â†’ Polish focus

#### 6. Data Loading & Preprocessing âœ“ ANSWERED
- Will you need:
  - On-the-fly augmentation (pitch shift, speed change, noise injection)? â†’ Probably yes
  - Different mixture types (anechoic, reverberant, dynamic mixing)? â†’ Reverberant yes
  - Variant selection (like your current MM-IPC system)? â†’ âœ“ Definitely
  - Different task modes beyond ES/EB/SB? â†’ Unknown
  - Memory-efficient loading for large datasets? â†’ Probably yes
- **Key constraint**: Augmentation should be modular (in dataset class only)

---

### ğŸ—ï¸ Model Architecture Requirements

#### 7. Model Selection Criteria
- What matters most for your experiments?
  - Maximum performance regardless of cost? â†’ No
  - Efficiency (real-time capable, low-resource)? â†’ âœ“ (deployment consideration)
  - Interpretability (understanding what the model learns)? â†’ Unknown
  - Diversity (comparing different architectural families)? â†’ âœ“
  - Specific properties (causal, streaming, online learning)? â†’ Unknown

#### 8. Model Configurations
- Will you need:
  - Different model sizes (small/medium/large) for the same architecture? â†’ Possibly
  - Pretrained models vs. training from scratch? â†’ Unknown
  - Fine-tuning capabilities? â†’ Unknown
  - Multi-task models (e.g., separation + enhancement)? â†’ âœ“ Very interesting
  - Curriculum learning or progressive training? â†’ Unknown

#### 9. Custom Modifications
- Might you need to:
  - Modify existing architectures (add/remove components)? â†’ Probably not
  - Experiment with different loss functions? â†’ Unknown
  - Try different optimization strategies? â†’ Unknown
  - Implement custom attention mechanisms or modules? â†’ Probably not

---

### ğŸ§ª Experimental Design

#### 10. Training Configurations
- How much flexibility do you need in:
  - Hyperparameter tuning (learning rates, batch sizes, schedulers)? â†’ Unknown
  - Regularization techniques (dropout, weight decay, data augmentation)? â†’ Unknown
  - Mixed precision training (AMP) vs. full precision? â†’ Already using AMP
  - Gradient accumulation strategies? â†’ Already using
  - Early stopping criteria? â†’ Unknown

#### 11. Experiment Tracking
- What information do you need to log?
  - Just final metrics, or full training curves? â†’ Probably both
  - Audio samples at checkpoints for listening tests? â†’ Unknown
  - Model predictions on specific test cases? â†’ Unknown
  - Computational resources (GPU memory, time, energy)? â†’ Probably yes (efficiency focus)
  - Intermediate representations (attention maps, embeddings)? â†’ Unknown

#### 12. Reproducibility
- How important is exact reproducibility?
  - Same results with same seed (strict)? â†’ Unknown
  - Similar trends (statistical reproducibility)? â†’ Unknown
  - Do you need to share code/models publicly? â†’ Unknown
  - Will you publish in venues requiring code release? â†’ Unknown

---

### ğŸ“ˆ Evaluation & Metrics

#### 13. Evaluation Metrics
- Beyond SI-SDR, what metrics matter for your thesis?
  - Perceptual metrics (PESQ, STOI)? â†’ âœ“ PESQ definitely, others unknown
  - Word Error Rate (if using ASR downstream)? â†’ Unknown
  - Computational metrics (latency, throughput, memory)? â†’ âœ“ (efficiency focus)
  - Subjective listening tests (MOS scores)? â†’ Unknown
  - Task-specific metrics (e.g., intelligibility for hearing aids)? â†’ No (not application-focused)

#### 14. Evaluation Scenarios âœ“ PARTIALLY ANSWERED
- What test conditions do you need?
  - Matched (train and test on same dataset)? â†’ âœ“
  - Cross-dataset (generalization)? â†’ âœ“ Definitely
  - Cross-language? â†’ Unknown
  - Different SNR levels? â†’ Unknown
  - Different number of speakers than training? â†’ No (2 speakers only)
  - Unseen background types? â†’ Probably yes

#### 15. Statistical Analysis
- Will you need:
  - Multiple runs with different seeds for statistical significance? â†’ Unknown
  - Confidence intervals or error bars? â†’ Unknown
  - Hypothesis testing (t-tests, ANOVA)? â†’ Unknown
  - Correlation analysis between metrics? â†’ Unknown

---

### ğŸ”„ Workflow & Usability

#### 16. User Interface
- How will you interact with the system?
  - Command-line only (current approach)? â†’ Probably yes
  - Configuration files (YAML) exclusively? â†’ Probably yes
  - Interactive notebooks for exploration? â†’ Unknown
  - Web interface for listening tests? â†’ Probably not
  - Automated pipelines for batch experiments? â†’ Unknown

#### 17. Experiment Management
- Do you need:
  - Automated hyperparameter search (grid, random, Bayesian)? â†’ Unknown
  - Experiment queuing system (run 10 experiments overnight)? â†’ Unknown
  - Resume from interruption (cluster preemption)? â†’ Unknown
  - Comparison dashboards (side-by-side results)? â†’ Unknown
  - Version control for experiments (like DVC, MLflow)? â†’ Unknown

#### 18. Output & Artifacts
- What do you need to save?
  - Only best checkpoint, or all checkpoints? â†’ Unknown
  - Separated audio files for qualitative analysis? â†’ Probably yes
  - Visualizations (spectrograms, attention maps)? â†’ Unknown
  - Summary tables (LaTeX format for thesis)? â†’ Probably yes
  - Intermediate results for debugging? â†’ Unknown

---

### âš™ï¸ Technical Constraints

#### 19. Computational Resources
- What hardware do you have access to?
  - Single GPU (what model?)? â†’ Unknown
  - Multiple GPUs (how many, distributed training)? â†’ Unknown
  - CPU-only fallback needed? â†’ Unknown
  - Cloud resources (AWS, Google Cloud)? â†’ Unknown
  - Time limits (cluster wall-time)? â†’ Unknown

#### 20. Dataset Storage
- Where will data live?
  - Local SSD (fast, limited space)? â†’ Current: local drives
  - Network storage (slower, more space)? â†’ Unknown
  - Cloud storage (S3, GCS)? â†’ Unknown
  - Need for lazy loading or caching strategies? â†’ Unknown

#### 21. Dependencies & Compatibility
- What matters for your environment?
  - Python version constraints? â†’ Currently Python 3.13
  - PyTorch version (1.x vs 2.x)? â†’ Unknown
  - CUDA version requirements? â†’ Unknown
  - Compatibility with university cluster? â†’ Unknown
  - Avoiding dependency conflicts between toolkits? â†’ Probably important

---

### ğŸ“… Timeline & Priorities

#### 22. Timeline
- When is your thesis due? â†’ Unknown
- How much time can you dedicate to:
  - Implementation/refactoring? â†’ Unknown
  - Running experiments? â†’ Unknown
  - Writing? â†’ Unknown
- What are the hard deadlines (proposal, defense, submission)? â†’ Unknown

#### 23. Milestones
- What do you need working by when?
  - Multi-dataset support for preliminary experiments? â†’ Unknown
  - All model architectures for main experiments? â†’ Unknown
  - Final results for thesis writing? â†’ Unknown
- Which features are must-haves vs. nice-to-haves? â†’ Unknown

#### 24. Risk Management
- What could go wrong?
  - Models don't converge on new datasets? â†’ Unknown
  - Not enough time for all planned experiments? â†’ Unknown
  - Hardware failures or access issues? â†’ Unknown
  - Unexpected poor results requiring pivot? â†’ Unknown
- What are your backup plans? â†’ Unknown

---

### ğŸ“ Academic Requirements

#### 25. Thesis Committee Expectations
- What does your committee value?
  - Novel contributions vs. thorough empirical work? â†’ Unknown
  - Theoretical depth vs. practical results? â†’ Unknown
  - Publications required before defense? â†’ Unknown
  - Software artifacts as contributions? â†’ Unknown

#### 26. Literature & Positioning
- How will your work fit in the literature?
  - Are you comparing to specific baselines (which ones)? â†’ Unknown
  - Following a specific research thread? â†’ Unknown
  - Addressing gaps identified by others? â†’ Unknown
  - Replicating/extending prior work? â†’ Unknown

#### 27. Publication Plans
- Do you plan to publish during your master's?
  - Conference papers (which venues, deadlines)? â†’ Unknown
  - Workshop papers? â†’ Unknown
  - Journal articles? â†’ Unknown
  - Open-source software releases? â†’ Unknown

---

### ğŸ” Edge Cases & Future-Proofing

#### 28. Extensibility
- Beyond datasets and models, might you need:
  - Different loss functions as modules? â†’ Possibly
  - Custom data augmentation strategies? â†’ âœ“ Yes (in dataset class)
  - Different input representations (waveform, spectrogram, features)? â†’ Unknown
  - Online learning or continuous adaptation? â†’ Unknown
  - Multi-stage pipelines (preprocessing + separation + postprocessing)? â†’ âœ“ (end-to-end vs modular)

#### 29. Collaboration
- Will others use your code?
  - Lab mates for their projects? â†’ Unknown
  - Advisor for demos/papers? â†’ Unknown
  - Future students building on your work? â†’ Unknown
  - Public release with documentation? â†’ Unknown

#### 30. Backwards Compatibility
- How important is it to:
  - Keep existing checkpoints loadable? â†’ Unknown
  - Maintain existing configuration files? â†’ Unknown
  - Support old experiment scripts? â†’ Unknown
  - Or: fresh start acceptable? â†’ Probably acceptable

---

### ğŸ¤” Meta Questions

#### 31. Learning Goals
- What do you want to learn from this project?
  - Deep understanding of separation architectures? â†’ Probably yes
  - Software engineering best practices? â†’ Probably yes
  - Experimental design skills? â†’ Probably yes
  - Specific techniques (transformers, state-space models)? â†’ Unknown

#### 32. Unknowns
- What don't you know yet that matters?
  - Which specific phenomena in PolSESS data to investigate? â†’ âœ“ Will clarify with new datasets
  - Whether Polish language has unique challenges? â†’ Unknown
  - How well existing models transfer to your data? â†’ Unknown
  - What your advisor expects? â†’ Unknown

---

## Design Philosophy Summary

### What You Want
1. **Modularity without bloat**
   - Core stays stable
   - Datasets and models as plugins
   - Easy to add new ones without touching core code

2. **Clean and readable code FIRST**
   - Not a commercial product
   - Demonstrates process and ideas
   - Educational value for understanding

3. **Research-focused, not production-focused**
   - Don't over-engineer
   - Don't optimize prematurely
   - Keep it simple

4. **Key constraint**: 8kHz, 2 speakers (simplifies everything)

### What You're Questioning
- Is `trainer_factory` necessary or is it over-engineering?
- Are we building the right abstractions?
- Will this approach work for your thesis needs?

---

## Next Steps

1. Validate architectural approach
2. Design simple, clean plugin system
3. Identify minimal set of abstractions needed
4. Ensure it supports your research goals without bloat

---

**Status**: Needs architectural proposal
**Key Decision**: Simplicity vs. Flexibility balance
